{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258fff3e",
   "metadata": {},
   "source": [
    "## LLM-as-a-Judge evaluation \n",
    "\n",
    "In this notebook, we test some approaches of evaluating responses Kai generates for different migration scenarios using an LLM as a judge.\n",
    "\n",
    "The responses are generated by running Kai manually in vscode with different models. The diff files of the responses are stored as artifacts for simplicity.\n",
    "\n",
    "#### Goal\n",
    "\n",
    "Goal of this exercise is to:\n",
    "- verify & finalize the evaluation metrics\n",
    "- finalize the evaluation prompts\n",
    "\n",
    "### Process\n",
    "\n",
    "Run Tools  -->  Run Kai (manual, responses collected)  -->  Run Tools  -->  Evaluate\n",
    "\n",
    "#### Running tools\n",
    "\n",
    "In this notebook, we run following tools before and after applying fixes from Kai:\n",
    "- `mvn compile`\n",
    "- `mvn test` (only if tests are present for a given test case)\n",
    "- `analyze` (kantra used for analysis)\n",
    "\n",
    "#### Evaluate\n",
    "\n",
    "For evaluating, three metrics are calculated:\n",
    "\n",
    "1. Completeness (C): Measures whether the issue is completely resolved\n",
    "2. Functional Parity (F): Measures whether existing functionality is maintained\n",
    "3. Knock-on Effort (E): Measures how much effort is needed to address new issues caused by the fix\n",
    "\n",
    "The total score is normalized for each metric and a final weighted score is produced between 0-10:\n",
    "\n",
    "```\n",
    "Final Score = 10 * (0.5 * C + 0.3 * F + 0.2 * E)\n",
    "```\n",
    "\n",
    "#### Pre-requisites\n",
    "\n",
    "- Create a virtualenv using Jupyter for running cells in this notebook. Use [requirements.txt](../requirements.txt) to install dependencies needed. \n",
    "- Copy the .env.sample file to .env. Select the model you want to use for evaluation - Only Bedrock and ChatOpenAI are supported. Add your LLM key for the model you want to use. Once setup, run the following cell to load .env file.\n",
    "- Make sure you have _java_ and _mvn_ installed.\n",
    "- Download the latest _kantra_ binary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad69a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec81130",
   "metadata": {},
   "source": [
    "Before we begin, we write some common code in the following cell which we will need later on. Run this cell before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0849885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some common functions we will need later on for the evaluation\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import subprocess\n",
    "import mplcursors\n",
    "from git import Repo\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Sequence, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "base_path_test_data = Path(\"test-data\").absolute()\n",
    "base_path_cloned_repos = (base_path_test_data / \"apps\")\n",
    "base_path_test_artifacts = (base_path_test_data / \"artifacts\")\n",
    "base_path_cloned_repos.mkdir(parents=True, exist_ok=True)\n",
    "base_path_test_artifacts.mkdir(parents=True, exist_ok=True)\n",
    "## NOTE: make sure this is correct for your system\n",
    "kantra_path = Path.home() / \".kantra\" / \"kantra\"\n",
    "## NOTE: set these values\n",
    "JAVA_HOME = Path(\"/usr/lib/jvm/java-21-openjdk/\")\n",
    "JAVA_BIN = JAVA_HOME / \"bin\"\n",
    "\n",
    "def parse_yaml(path: Path): \n",
    "    with open(path, \"r\") as f: return yaml.safe_load(f)\n",
    "\n",
    "def parse_yaml_key(tc_path: str, key: str):\n",
    "    parsed = parse_yaml(tc_path)\n",
    "    return parsed.get(key)\n",
    "\n",
    "@dataclass\n",
    "class TestAppCoords:\n",
    "    path: Path\n",
    "    \n",
    "    name: str = \"__unpopulated__\"\n",
    "    repo_path: Path = Path(\"__unpopulated__\")\n",
    "    url: str = \"__unpopulated__\"\n",
    "    branch: str = \"__unpopulated__\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        parsed = parse_yaml(self.path)\n",
    "        self.name = parsed.get(\"name\")\n",
    "        self.url = parsed.get(\"source_code\").get(\"git\").get(\"url\")\n",
    "        self.branch = parsed.get(\"source_code\").get(\"git\").get(\"branch\")\n",
    "        self.repo_path = base_path_cloned_repos / self.name\n",
    "\n",
    "@dataclass\n",
    "class TestCaseCoords:\n",
    "    path: Path\n",
    "    variant: str\n",
    "    diff_path: Path\n",
    "    app_coords: TestAppCoords\n",
    "\n",
    "    name: str = \"__unpopulated__\"\n",
    "    description: str = \"__unpopulated__\"\n",
    "    targets: list[str] = field(default_factory=list)\n",
    "    test_selectors: list[str] = field(default_factory=list)\n",
    "    base_path_before_artifacts: Path = Path(\"__unpopulated__\")\n",
    "    base_path_after_artifacts: Path = Path(\"__unpopulated__\")\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        parsed = parse_yaml(self.path)\n",
    "        self.name = parsed.get(\"name\")\n",
    "        self.description = parsed.get(\"description\")\n",
    "        self.targets = parse_yaml_key(self.app_coords.path, \"targets\")\n",
    "        self.test_selectors = parse_yaml_key(self.path, \"testSelectors\")\n",
    "        self.base_path_before_artifacts = base_path_test_artifacts / self.app_coords.name / self.name /self.variant / \"before\"\n",
    "        self.base_path_after_artifacts = base_path_test_artifacts / self.app_coords.name / self.name / self.variant / \"after\"\n",
    "        self.base_path_before_artifacts.mkdir(parents=True, exist_ok=True)\n",
    "        self.base_path_after_artifacts.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def clone_repo(url: str, branch: str, path: Path):\n",
    "    try:\n",
    "        Repo.clone_from(url, depth=1, single_branch=True, branch=branch, to_path=path)\n",
    "    except Exception as e:\n",
    "        if \"already exists\" not in str(e):\n",
    "            print(\"fatal error cloning repo\")\n",
    "            sys.exit(1)\n",
    "\n",
    "def get_model():\n",
    "    provider = os.getenv(\"model_provider\")\n",
    "    model_id = os.getenv(\"model_id\")\n",
    "    if not model_id or not provider:\n",
    "        raise ValueError(\"model_id and/or model_provider are not set\")\n",
    "    match provider:\n",
    "        case \"chatbedrock\":\n",
    "            key_id = os.getenv(\"aws_access_key_id\")\n",
    "            access_key = os.getenv(\"aws_secret_access_key\")\n",
    "            region = os.getenv(\"region\")\n",
    "            if not region or not access_key or not key_id:\n",
    "                raise ValueError(\"aws_region and/or aws_secret_access_key and/or aws_access_key_id is not set\")\n",
    "            return ChatBedrockConverse(\n",
    "                model_id=model_id,\n",
    "                aws_access_key_id=key_id,\n",
    "                aws_secret_access_key=access_key,\n",
    "                region_name=region,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "        case \"chatopenai\":\n",
    "            api_key = os.getenv(\"OPEANAI_API_KEY\") or os.getenv(\"api_key\")\n",
    "            if not api_key:\n",
    "                raise ValueError(\"OPEANAI_API_KEY or api_key is not set\")\n",
    "            return ChatOpenAI(model=model_id, api_key=api_key, temperature=0.0)\n",
    "        case _:\n",
    "            raise ValueError(f\"Invalid model provider: {provider}\")\n",
    "\n",
    "def run_command(cmd: list[str], stdout_path: Path, stderr_path: Path, cwd: Path, env_vars: dict[str, str] = {}):\n",
    "    pwd = os.getcwd()\n",
    "    os.chdir(cwd)\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env_vars)\n",
    "    with open(stdout_path, \"w\") as f:\n",
    "        f.write(result.stdout)\n",
    "    with open(stderr_path, \"w\") as f:\n",
    "        f.write(result.stderr)\n",
    "    os.chdir(pwd)\n",
    "\n",
    "def git_apply_diff(tc: TestCaseCoords):\n",
    "    repo = Repo(tc.app_coords.repo_path)\n",
    "    repo.git.apply(tc.diff_path)\n",
    "\n",
    "def git_reset(tc: TestCaseCoords):\n",
    "    repo = Repo(tc.app_coords.repo_path)\n",
    "    repo.git.reset(\"--hard\")\n",
    "\n",
    "def run_mvn(tc: TestCaseCoords, after: bool = False, env_vars: dict[str, str] = {}):\n",
    "    base_path = (tc.base_path_after_artifacts if after else tc.base_path_before_artifacts) / \"mvn\"\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    run_command(\n",
    "        cmd=[\"mvn\", \"compile\"], \n",
    "        stdout_path=base_path / \"mvn_compile.log\",\n",
    "        stderr_path=base_path / \"mvn_compile.err\", \n",
    "        cwd=tc.app_coords.repo_path,\n",
    "        env_vars=env_vars,\n",
    "    )\n",
    "\n",
    "def run_mvn_test(tc: TestCaseCoords, after: bool = False, env_vars: dict[str, str] = {}):\n",
    "    base_path = (tc.base_path_after_artifacts if after else tc.base_path_before_artifacts) / \"mvn\"\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    run_command(\n",
    "        cmd=[\"mvn\", \"test\", f\"-Dtest={','.join(tc.test_selectors)}\"], \n",
    "        stdout_path=base_path / \"mvn_test.log\",\n",
    "        stderr_path=base_path / \"mvn_test.err\", \n",
    "        cwd=tc.app_coords.repo_path,\n",
    "        env_vars=env_vars,\n",
    "    )\n",
    "\n",
    "def run_kantra(tc: TestCaseCoords, after: bool = False, env_vars: dict[str, str] = {}):\n",
    "    base_path = (tc.base_path_after_artifacts if after else tc.base_path_before_artifacts) / \"kantra\"\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    kantra_cmd = [\n",
    "        kantra_path, \"analyze\", \"--overwrite\", \n",
    "        \"--input\", tc.app_coords.repo_path, \n",
    "        \"--output\", base_path\n",
    "    ]\n",
    "    for target in tc.targets:\n",
    "        kantra_cmd.append(\"--target\")\n",
    "        kantra_cmd.append(target.strip('\"'))\n",
    "    env_vars = os.environ.copy()\n",
    "    env_vars[\"JAVA_HOME\"] = JAVA_HOME\n",
    "    env_vars[\"PATH\"] = os.environ[\"PATH\"] + \":\" + str(JAVA_BIN)\n",
    "    run_command(\n",
    "        cmd=kantra_cmd, \n",
    "        stdout_path=base_path / \"kantra.log\", \n",
    "        stderr_path=base_path / \"kantra.err\", \n",
    "        cwd=tc.app_coords.repo_path,\n",
    "        env_vars=env_vars,\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ExperimentResults:\n",
    "    title: str\n",
    "    completeness: float \n",
    "    functional_parity: float\n",
    "    residual_effort: float\n",
    "\n",
    "def plot_scores_grouped(\n",
    "    experiments: Sequence[Sequence[ExperimentResults]],\n",
    "    experiment_titles: Sequence[str],\n",
    "    weights: tuple[float, float, float] = (0.5, 0.3, 0.2),\n",
    "    scale: float = 10.0,\n",
    "    colors: Optional[tuple[str, str, str]] = None,\n",
    "    figsize: tuple[float, float] = (9, 0.9),\n",
    "):\n",
    "    assert len(experiments) == len(experiment_titles), \"titles must match experiments\"\n",
    "    if colors is None:\n",
    "        colors = (\"deepskyblue\", \"mediumaquamarine\", \"sandybrown\")\n",
    "    comp_names = (\"C (50%)\", \"FP (30%)\", \"R (20%)\")\n",
    "    wC, wFP, wR = weights\n",
    "    y_positions, y_labels = [], []\n",
    "    y = 0.0\n",
    "    intra_step = 1.0\n",
    "    inter_gap_extra = 0.6  # extra space after each experiment\n",
    "    bars = []  # keep handles for optional tooltips\n",
    "    fig, ax = plt.subplots(figsize=(figsize[0], max(figsize[1], 0.6 + 0.45 * sum(len(vs) for vs in experiments))))\n",
    "    for exp_idx, (title, variants) in enumerate(zip(experiment_titles, experiments)):\n",
    "        for var in variants:\n",
    "            cC = scale * wC * var.completeness\n",
    "            cFP = scale * wFP * var.functional_parity\n",
    "            cR = scale * wR * var.residual_effort\n",
    "            contribs = (cC, cFP, cR)\n",
    "            total = sum(contribs)\n",
    "            left = 0.0\n",
    "            for contrib, cname, color in zip(contribs, comp_names, colors):\n",
    "                h = ax.barh(y, contrib, left=left, label=cname, color=color)\n",
    "                # stash metadata for tooltips\n",
    "                bars.append((h[0], {\n",
    "                    \"experiment\": title,\n",
    "                    \"variant\": var.title,\n",
    "                    \"component\": cname,\n",
    "                    \"value\": contrib,\n",
    "                    \"total\": total\n",
    "                }))\n",
    "                left += contrib\n",
    "            y_positions.append(y)\n",
    "            label = f\"{title}: {var.title}\" if len(variants) > 1 else title\n",
    "            y_labels.append(label)\n",
    "            y += intra_step\n",
    "\n",
    "        y += inter_gap_extra\n",
    "\n",
    "    # Axes cosmetics\n",
    "    ax.set_xlim(0, scale)\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_xlabel(f\"Weighted Score (0–{int(scale)})\")\n",
    "    ax.set_title(\"Experiment Scores\")\n",
    "    ax.grid(axis=\"x\", linestyle=\":\", alpha=0.35)\n",
    "    # Remove legend per requirement\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.remove()\n",
    "\n",
    "    cursor = mplcursors.cursor([b for b, _ in bars], hover=True)\n",
    "    @cursor.connect(\"add\")\n",
    "    def _on_add(sel):\n",
    "        artist = sel.artist\n",
    "        meta = next((m for b, m in bars if b is artist), None)\n",
    "        if meta:\n",
    "            sel.annotation.set_text(\n",
    "                f\"{meta['experiment']}\\n{meta['variant']}\\n\"\n",
    "                f\"{meta['component']}: {meta['value']:.2f}\\n\"\n",
    "                f\"Total: {meta['total']:.2f}\"\n",
    "            )\n",
    "        sel.annotation.get_bbox_patch().set_alpha(0.9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06761bb",
   "metadata": {},
   "source": [
    "In the following cell, we have our LLM-as-a-Judge code. Run this cell before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd38dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from git import Repo, Head\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "from dataclasses import dataclass, field\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "@dataclass\n",
    "class EvaluationTools:\n",
    "    tc: TestCaseCoords\n",
    "\n",
    "    changed_filepaths: list[str] = field(default_factory=list)\n",
    "    changed_filelist: list[str] = field(default_factory=list)\n",
    "    changed_files: list[str] = field(default_factory=dict)\n",
    "    architecture_md: str = \"Not available\"\n",
    "\n",
    "    def init(self):\n",
    "        self.architecture_md = (self.tc.app_coords.path.parent / \"architecture.md\").read_text()\n",
    "        self.repo = Repo(self.tc.app_coords.repo_path)\n",
    "        self.repo.git.reset(\"--hard\")\n",
    "        self.repo.git.apply(self.tc.diff_path)\n",
    "        self.changed_filepaths = self.repo.git.diff(\"--name-only\").split()\n",
    "        self.changed_filelist = [\n",
    "            str(p.relative_to(self.tc.app_coords.repo_path))\n",
    "            for p in Path(self.tc.app_coords.repo_path).rglob(\"*\")\n",
    "            if p.is_file() and not any(part.startswith(\".\") or part.startswith(\"target\") for part in p.relative_to(self.tc.app_coords.repo_path).parts)\n",
    "        ]\n",
    "        for path in self.changed_filepaths:\n",
    "            self.changed_files[path] = (self.tc.app_coords.repo_path / Path(path)).read_text()\n",
    "        self.repo.git.reset(\"--hard\")\n",
    "\n",
    "    def get_architecture_tool(self):\n",
    "        architecture_md = self.architecture_md\n",
    "        @tool\n",
    "        def get_architecture():\n",
    "            \"\"\"Returns the architecture of the application in markdown format\"\"\"\n",
    "            return architecture_md\n",
    "        return get_architecture\n",
    "    \n",
    "    def get_changed_files_tool(self):\n",
    "        changed_filepaths = self.changed_filepaths\n",
    "        @tool\n",
    "        def get_changed_files():\n",
    "            \"\"\"Returns the list of files that have been changed after applying the fixes\"\"\"\n",
    "            return \"\\n\".join(changed_filepaths)\n",
    "        return get_changed_files\n",
    "    \n",
    "    def get_file_content_tool(self):\n",
    "        changed_files = self.changed_files\n",
    "        repo_path = self.tc.app_coords.repo_path\n",
    "        @tool\n",
    "        def get_file_content(\n",
    "            file_path: Annotated[str, \"Relative path to the file\"],\n",
    "            pre_migration: Annotated[bool, \"Return a pre-migration version, defaults to False\"] = False):\n",
    "            \"\"\"Returns the current content of a file, if pre_migration is set, returns its old content\"\"\"\n",
    "            if pre_migration or file_path not in self.changed_files:\n",
    "                return (repo_path / file_path).read_text()\n",
    "            return changed_files[file_path]\n",
    "        return get_file_content\n",
    "\n",
    "    def get_list_files_tool(self):\n",
    "        changed_filelist = self.changed_filelist\n",
    "        repo_path = self.tc.app_coords.repo_path\n",
    "        @tool\n",
    "        def list_files(\n",
    "            pattern: Annotated[str, \"Python regex pattern to match files against\"],\n",
    "            pre_migration: Annotated[bool, \"Set to True to return pre-migration list of files, defaults to False\"] = False):\n",
    "            \"\"\"Returns a list of files in the source code matching given pattern\"\"\"\n",
    "            all_files = changed_filelist\n",
    "            if pre_migration:\n",
    "                all_files = [str(p.relative_to(repo_path)) \n",
    "                    for p in Path(repo_path).rglob(\"*\")\n",
    "                    if p.is_file() and not any(part.startswith(\".\") or part.startswith(\"target\") for part in p.relative_to(self.repo_path).parts)]\n",
    "            return \"\\n\".join([f for f in all_files.split(\"\\n\") if re.match(pattern, f)])\n",
    "        return list_files\n",
    "    \n",
    "    def get_test_output_tool(self):\n",
    "        before_tests: Path = self.tc.base_path_before_artifacts / \"mvn\" / \"mvn_test.log\"\n",
    "        after_tests: Path = self.tc.base_path_after_artifacts / \"mvn\" / \"mvn_test.log\"\n",
    "        @tool\n",
    "        def get_test_output(\n",
    "            pre_migration: Annotated[bool, \"Set to True to return pre-migration test output, defaults to False\"] = False,\n",
    "        ):\n",
    "            \"\"\"Returns results of the applicable behavioral tests\"\"\"\n",
    "            if pre_migration and before_tests.exists():\n",
    "                return before_tests.read_text()\n",
    "            elif not pre_migration and after_tests.exists():\n",
    "                return after_tests.read_text()\n",
    "            return \"Tests not available\"\n",
    "        return get_test_output\n",
    "    \n",
    "    def get_kantra_output_diff_tool(self):\n",
    "        before_kantra: Path = self.tc.base_path_before_artifacts / \"kantra\" / \"output\" / \"output.yaml\"\n",
    "        after_kantra: Path = self.tc.base_path_after_artifacts / \"kantra\" / \"output\" / \"output.yaml\"\n",
    "        @tool\n",
    "        def get_static_analysis_issues_post_migration():\n",
    "            \"\"\"Returns new migration issues introduced after the migration fix\"\"\"\n",
    "            return after_kantra.read_text() - before_kantra.read_text()\n",
    "        return get_static_analysis_issues_post_migration\n",
    "    \n",
    "    def get_compilation_issues_post_migration_tool(self):\n",
    "        after_compilation: Path = self.tc.base_path_after_artifacts / \"mvn\" / \"mvn_compile.log\"\n",
    "        @tool\n",
    "        def get_compilation_issues_post_migration():\n",
    "            \"\"\"Returns new compilation issues introduced after the migration fix\"\"\"\n",
    "            return after_compilation.read_text()\n",
    "        return get_compilation_issues_post_migration\n",
    "\n",
    "@dataclass\n",
    "class EvaluationInput:\n",
    "    source_tech: str\n",
    "    target_tech: str\n",
    "    issue: str\n",
    "    issue_notes: str\n",
    "    tc_path: Path\n",
    "    tools: EvaluationTools\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResults:\n",
    "    score: float = 0.0\n",
    "    responses: list[any] = field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82723648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_completeness_agent(\n",
    "    inp: EvaluationInput\n",
    ") -> EvaluationResults:\n",
    "    COMPLETENESS_PROMPTS = {\n",
    "    \"system\": \"\"\"You are a senior software engineer expert in migrating applications from one technology to another.\"\"\",\n",
    "    \"user_summarize\": \"\"\"You are reviewing a code change made to fix a migration issue identified by a static analysis tool.\n",
    "The application is being migrated from {source_tech} to {target_tech}.\n",
    "You are provided with:\n",
    "- The original issue description\n",
    "- Developer notes describing the intended fix (consider these the only source of truth)\n",
    "- Access to a set of tools that can inspect the codebase\n",
    "\n",
    "## Your task\n",
    "\n",
    "Determine how completely the code changes implement the fix as described in the developer notes—no more, no less.\n",
    "Your job is to compare implementation (actual code) against intent (developer notes).\n",
    "\n",
    "## Evaluation Rules\n",
    "\n",
    "- Stick strictly to the notes when comparing. They are the authoritative reference.\n",
    "- Do not assume additional requirements, behaviors, or conventions.\n",
    "- Use tools thoughtfully. Only gather information necessary to confirm alignment between the notes and the actual code changes.\n",
    "- Be specific. When identifying missing or incomplete work, clearly describe what evidence led you to that conclusion.\n",
    "- Be concise but thorough. Focus on correctness and completeness.\n",
    "- Refer explicitly to evidence from the codebase when making your assessment.\n",
    "- Avoid subjective language like \"it seems\" or \"probably\".\n",
    "\n",
    "There are three possible outcomes for your evaluation:\n",
    "\n",
    "1. COMPLETELY_FIXED:\n",
    "   - All changes described in the notes are present and correctly implemented.\n",
    "   - No missing, incorrect, or contradictory work remains.\n",
    "2. PARTIALLY_FIXED:\n",
    "   - Some changes described in the notes are implemented, but at least one required modification is missing, incorrect, or incomplete.\n",
    "3. UNFIXED:\n",
    "   - *None* of the changes described in the notes are addressed.\n",
    "   - OR, the changes leave the code in a broken state.\n",
    "\n",
    "## Output Format\n",
    "\n",
    "If the issue is completely fixed, respond in the following format:\n",
    "\n",
    "```\n",
    "COMPLETELY_FIXED\n",
    "\n",
    "<Brief summary explaining how the implemented changes align exactly with the notes and fully resolve the issue.>\n",
    "```\n",
    "\n",
    "If the issue is partially fixed, identify outstanding changes. Try to group them logically together to keep the changes distinct.\n",
    "Respond in the following format:\n",
    "\n",
    "```\n",
    "PARTIALLY_FIXED\n",
    "\n",
    "<Brief summary explaining why the fix is incomplete or incorrect, and what parts are missing or deviate from the notes.>\n",
    "\n",
    "## Outstanding issues\n",
    "\n",
    "1. <First issue summary>\n",
    "2. <Second issue summary>\n",
    "...\n",
    "```\n",
    "\n",
    "If the issue is not fixed at all, respond in the following format:\n",
    "\n",
    "```\n",
    "UNFIXED\n",
    "\n",
    "<Brief summary explaining why you think the issue is completely unfixed.>\n",
    "```\n",
    "\n",
    "\n",
    "Here are your inputs:\n",
    "## The issue identified was:\n",
    "{issue}\n",
    "\n",
    "## Here are the notes about the issue:\n",
    "{issue_notes}\n",
    "\"\"\",\n",
    "    \"user_rate\": \"\"\"We used a static analysis tool to identify a migration issue in the application which needs to be migrated from {source_tech} to {target_tech}.\n",
    "We fixed the issue and asked a senior software engineer to review the changes. The engineer reviewed the changes and provided a summary of the changes made.\n",
    "\n",
    "## Your task\n",
    "\n",
    "Your goal is to:\n",
    "\n",
    "- Analyze each *distinct unresolved issue* described in the summary.\n",
    "- Assess the complexity of fixing each issue for given application.\n",
    "- Finally, provide a rating for every issue based on the following scale:\n",
    "    - TRIVIAL_CHANGES_NEEDED: Requires only a few small, localized modifications to files in the codebase (e.g., renaming, updating a parameter, minor logic tweak, or adding a missing import).\n",
    "    - COMPLEX_CHANGES_NEEDED: Requires multiple related changes across files, complex logic changes, or coordination between components or services.\n",
    "    - REDESIGN_NEEDED: Indicates a fundamental design or architectural flaw requiring a significant refactor or reimplementation of core logic.\n",
    "\n",
    "## Guidelines\n",
    "- Focus only on issues explicitly described in the summary.\n",
    "- Do not invent or infer new issues beyond what is stated.\n",
    "- Use architectural reasoning (e.g., cross-file dependencies, data flow, API contracts) to decide the appropriate rating.\n",
    "- Each issue should have a short justification describing why it falls into that category.\n",
    "- Maintain objectivity — avoid vague or subjective language like “probably complex” or “seems fine.”\n",
    "- If there are no issues identified in the summary, rate the migration as COMPLETE.\n",
    "- Look at architecture of the application to help you make the decision.\n",
    "\n",
    "Produce your response in following format:\n",
    "\n",
    "```\n",
    "---\n",
    "<Issue title>\n",
    "<Brief reasoning (2~3 lines) behind the rating.>\n",
    "Rating: <TRIVIAL_CHANGES_NEEDED | COMPLEX_CHANGES_NEEDED | REDESIGN_NEEDED>\n",
    "---\n",
    "<Issue 2 title>\n",
    "<Brief reasoning (2~3 lines) behind the rating.>\n",
    "Rating: <TRIVIAL_CHANGES_NEEDED | COMPLEX_CHANGES_NEEDED | REDESIGN_NEEDED>\n",
    "...\n",
    "```\n",
    "\n",
    "Here are your inputs:\n",
    "\n",
    "## Issue we fixed\n",
    "{issue}\n",
    "\n",
    "## Summary\n",
    "{summary}\n",
    "\"\"\",\n",
    "}\n",
    "    responses = []\n",
    "    agent = create_react_agent(\n",
    "        model=get_model(),\n",
    "        tools=[\n",
    "            inp.tools.get_architecture_tool(),\n",
    "            inp.tools.get_changed_files_tool(),\n",
    "            inp.tools.get_file_content_tool(),\n",
    "        ],\n",
    "        prompt=COMPLETENESS_PROMPTS[\"system\"],\n",
    "    )\n",
    "    response = agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": COMPLETENESS_PROMPTS[\"user_summarize\"].format(\n",
    "                        source_tech=inp.source_tech,\n",
    "                        target_tech=inp.target_tech,\n",
    "                        issue=inp.issue,\n",
    "                        issue_notes=inp.issue_notes,\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        { \"recursion_limit\": 50 }\n",
    "    )\n",
    "    responses.append(response)\n",
    "    summarized_content: str = response[\"messages\"][-1].content\n",
    "    \n",
    "    # return binary answers first\n",
    "    if \"UNFIXED\" in summarized_content:\n",
    "        return 0\n",
    "    elif \"COMPLETELY_FIXED\" in summarized_content:\n",
    "        return 1\n",
    "    \n",
    "    # for partial fixes, a base score of 0.2 will be added\n",
    "    rate_agent = create_react_agent(\n",
    "        model=get_model(),\n",
    "        tools=[inp.tools.get_architecture_tool()],\n",
    "        prompt=COMPLETENESS_PROMPTS[\"system\"],\n",
    "    )\n",
    "    response = rate_agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": COMPLETENESS_PROMPTS[\"user_rate\"].format(\n",
    "                        source_tech=inp.source_tech,\n",
    "                        target_tech=inp.target_tech,\n",
    "                        issue=inp.issue,\n",
    "                        summary=response[\"messages\"][-1].content,\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        { \"recursion_limit\": 50 }\n",
    "    )\n",
    "    rating_content: str = response[\"messages\"][-1].content\n",
    "    score = 0.8\n",
    "    METRICS = {\n",
    "        \"TRIVIAL_CHANGES_NEEDED\": 0.05,\n",
    "        \"COMPLEX_CHANGES_NEEDED\": 0.2,\n",
    "        \"REDESIGN_NEEDED\": 0.7,\n",
    "    }\n",
    "    for line in rating_content.split(\"\\n\"):\n",
    "        match = re.search(r\"Rating:\\s*([^\\n\\r]+)\", line)\n",
    "        if match:\n",
    "            val = float(METRICS.get(match.group(1).strip()))\n",
    "            score -= val\n",
    "    responses.append(response)\n",
    "    return EvaluationResults(\n",
    "        score=round(max(score + 0.2, 0), 2),\n",
    "        responses=responses,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6f62285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_functional_correctness_agent(\n",
    "    inp: EvaluationInput\n",
    "):\n",
    "    FUNCTIONAL_CORRECTNESS_PROMPTS = {\n",
    "        \"system\": \"You are a senior engineering expert in migrating source code as well as reviewing source code that is migrated from {source_tech} to {target_tech}.\",\n",
    "        \"user_summarize\": \"\"\"You are overseeing migration of a codebase from {source_tech} to {target_tech}.\n",
    "You are evaluating whether the migrated code preserves the functional behavior of its pre-migration version.\n",
    "\n",
    "You are given:\n",
    "- The original migration issue being fixed.\n",
    "- Various tools to access post migration artifacts such as changed files, contents of pre and post migration files, results of behavioral tests (if present) and more.\n",
    "\n",
    "## Your task\n",
    "\n",
    "Determine if the post-migration code behaves functionally equivalent to the pre-migration code.\n",
    "Focus strictly on runtime behavior, input/output consistency, and side effects.\n",
    "Ignore stylistic, architectural, or performance differences unless they alter functional outcomes.\n",
    "\n",
    "* Evidence-driven only.\n",
    "- Base all reasoning on observable evidence from code or test results.\n",
    "- Never assume developer intent beyond provided inputs.\n",
    "\n",
    "* Understand the baseline.\n",
    "- Examine the pre-migration code for:\n",
    "  - Control flow and data flow\n",
    "  - API contracts and return values\n",
    "  - Input constraints and edge-case handling\n",
    "  - External side effects (I/O, state changes, dependencies)\n",
    "\n",
    "* Compare precisely.\n",
    "- For each changed function or module, verify:\n",
    "  - Input/Output equivalence\n",
    "  - Algorithmic logic and branching consistency\n",
    "  - Data transformations and validation rules\n",
    "  - Exception and error handling behavior\n",
    "  - API interface and dependency interactions\n",
    "- Anchor every claim to evidence (specific functions, variables, or test traces).\n",
    "- Differentiate functional logic vs configuration/environment clearly.\n",
    "- Avoid judgmental or speculative phrasing — report observations only.\n",
    "- Use deterministic comparisons: “X no longer calls Y,” “Return type changed from boolean to ResponseEntity,” etc.\n",
    "\n",
    "* Handle tests carefully.\n",
    "- Ignore failures caused purely by environment/config differences (e.g., path changes, dependency injection mismatches).\n",
    "- Treat failures that reflect logic or data regressions as evidence of non-equivalence.\n",
    "- Even if the tests fail, carefully analyze the test code itself to see if the functionality its testing is preserved.\n",
    "\n",
    "* Do not overreach.\n",
    "- Do not infer new requirements, “intended” fixes, or performance expectations.\n",
    "- This is not a code-quality or completeness evaluation — only functional equivalence.\n",
    "\n",
    "## Output requirements\n",
    "\n",
    "- Summarize concrete evidence for any differences affecting functionality.\n",
    "- Group related findings into distinct, logically separate issues.\n",
    "- Provide a rating for the functional parity based on the scale below:\n",
    "  - EQUIVALENT\n",
    "    - Full behavioral parity. All functional logic and data flow preserved.\n",
    "    - All tests pass or only harness/config mismatches.\n",
    "    - Identical algorithms, APIs, and side effects.\n",
    "  - CLOSELY_EQUIVALENT\n",
    "    - Parity in business logic; minor config or integration adjustments needed.\n",
    "    - Failing tests traceable solely to environment or dependency setup.\n",
    "    - Code identical except for platform-specific or annotation-level differences.\n",
    "  - SOMEWHAT_EQUIVALENT\n",
    "    - Core logic intact but minor deviations exist (e.g., missing validation, altered edge case).\n",
    "    - Some functional tests fail; failures fixable via small code edits.\n",
    "    - Small discrepancies in conditions, defaults, or error handling.\n",
    "  - NOT_EQUIVALENT\n",
    "    - Major behavioral divergence — functionality changed, omitted, or broken.\n",
    "    - Tests fail due to true logic or data-flow regressions.\n",
    "    - Missing branches, incorrect return paths, lost side effects, or altered API behavior.\n",
    "\n",
    "Produce your output in format below:\n",
    "\n",
    "```\n",
    "<Brief, objective reasoning for every distinct issue you found — reference specific files, functions, or behaviors as evidence.>\n",
    "\n",
    "Rating: <EQUIVALENT | CLOSELY_EQUIVALENT | SOMEWHAT_EQUIVALENT | NOT_EQUIVALENT>\n",
    "\n",
    "```\n",
    "\n",
    "Here are your inputs:\n",
    "\n",
    "## Original issue\n",
    "\n",
    "{issue}\n",
    "\n",
    "## Applicable behvioral tests\n",
    "{test_selectors}\n",
    "\"\"\",\n",
    "    }\n",
    "    responses = []\n",
    "    summarize_agent = create_react_agent(\n",
    "        model=get_model(),\n",
    "        tools=[\n",
    "            inp.tools.get_architecture_tool(),\n",
    "            inp.tools.get_changed_files_tool(),\n",
    "            inp.tools.get_file_content_tool(),\n",
    "            inp.tools.get_list_files_tool(),\n",
    "            inp.tools.get_test_output_tool(),\n",
    "        ],\n",
    "        prompt=FUNCTIONAL_CORRECTNESS_PROMPTS[\"system\"].format(\n",
    "            source_tech=inp.source_tech,\n",
    "            target_tech=inp.target_tech,\n",
    "        ),\n",
    "    )\n",
    "    test_selectors=parse_yaml_key(inp.tc_path, \"testSelectors\")\n",
    "    resopnse = summarize_agent.invoke(\n",
    "      {\n",
    "        \"messages\": [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": FUNCTIONAL_CORRECTNESS_PROMPTS[\"user_summarize\"].format(\n",
    "                  source_tech=inp.source_tech,\n",
    "                  target_tech=inp.target_tech,\n",
    "                  issue=inp.issue,\n",
    "                  test_selectors=\"\\n- \".join(test_selectors) if test_selectors != \"__unknown__\" else \"Not available\",\n",
    "              )\n",
    "          },\n",
    "        ],\n",
    "      },\n",
    "      { \"recursion_limit\": 50 }\n",
    "    )\n",
    "    responses.append(resopnse)\n",
    "    for line in resopnse[\"messages\"][-1].content.split(\"\\n\"):\n",
    "        match = re.search(r\"Rating:\\s*([^\\n\\r]+)\", line)\n",
    "        if match:\n",
    "            val = float({\n",
    "              \"EQUIVALENT\": 1,\n",
    "              \"CLOSELY_EQUIVALENT\": 0.75,\n",
    "              \"SOMEWHAT_EQUIVALENT\": 0.5,\n",
    "              \"NOT_EQUIVALENT\": 0,\n",
    "            }.get(match.group(1).strip()))\n",
    "            return EvaluationResults(\n",
    "                score=val,\n",
    "                responses=responses,\n",
    "            )\n",
    "    raise Exception(\"No rating found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3691a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_residual_effort_agent(\n",
    "    inp: EvaluationInput\n",
    "):\n",
    "    RESIDUAL_EFFORT_PROMPTS = {\n",
    "        \"system\": \"You are a senior engineering expert in migrating source code as well as reviewing source code that is migrated from {source_tech} to {target_tech}.\",\n",
    "        \"user_summarize\": \"\"\"You are overseeing migration of a codebase from {source_tech} to {target_tech}.\n",
    "You are evaluating the impact of changes made to the codebase to fix a migration issue.\n",
    "After fixing a specific migration issue, the compilation/build and static analysis tools were re-run.\n",
    "These tools have reported new issues — some may be compilation or build errors, while others may be new migration issues identified by the migration analyzer.\n",
    "Your task is to determine what new issues were introduced, how severe they are, and how complex it would be to fix them.\n",
    "\n",
    "You are given:\n",
    "- The original migration issue being fixed.\n",
    "- Various tools to access post migration artifacts such as compilation / build and static analysis tooling post migration, changed files, contents of pre and post migration files, among others.\n",
    "\n",
    "## Your task\n",
    "\n",
    "Evaluate the *impact* and *complexity* of newly introduced issues after applying the migration fix.\n",
    "\n",
    "Follow a deterministic, evidence-based process as described below:\n",
    "\n",
    "* Understand the new issues\n",
    "- Collect all new issues reported after the fix — both from build/compilation logs and static analysis tools.\n",
    "- Distinguish between:\n",
    "  - Compilation / Build issues (syntax, missing symbols, type mismatches, dependency errors, etc.)\n",
    "  - Migration issues (detected by static analysis tooling that verifies framework-specific rules or patterns).\n",
    "- Group the new issues into distinct, logically separate issues. For instance, multiple issues may be fixed by a single fix. Or, more than one issues may be closely related to each other requiring interdependent fixes.\n",
    "  - Multiple tool reports that stem from one root cause → treat as one issue.\n",
    "  - Separate unrelated failures → treat as different issues.\n",
    "\n",
    "* Evidence-driven only.\n",
    "- For each distinct issue:\n",
    "  - Inspect pre- and post-migration code to determine what caused it.\n",
    "  - Identify:\n",
    "    - Impacted functions, modules, or APIs\n",
    "    - Root cause (e.g., missing import, incompatible API call, incorrect type adaptation)\n",
    "    - Possible scope of fix (localized vs. cross-component)\n",
    "\n",
    "* Compare precisely.\n",
    "- Anchor every claim to evidence (specific functions, variables, or test traces).\n",
    "- Avoid judgmental or speculative phrasing — report observations only.\n",
    "\n",
    "* Do not overreach.\n",
    "- Do not infer new requirements, “intended” fixes, or performance expectations.\n",
    "- This is not a code-quality or completeness evaluation — only functional equivalence.\n",
    "\n",
    "## Output requirements\n",
    "\n",
    "- For each *logically distinct* issue, provide a work estimate for fixing the issue on a scale given below:\n",
    "    - TRIVIAL_CHANGES_NEEDED: Requires only a few small, localized modifications to files in the codebase (e.g., renaming, updating a parameter, minor logic tweak, or adding a missing import).\n",
    "    - COMPLEX_CHANGES_NEEDED: Requires multiple related changes across files, complex logic changes, or coordination between components or services.\n",
    "    - REDESIGN_NEEDED: Indicates a fundamental design or architectural flaw requiring a significant refactor or reimplementation of core logic.\n",
    "\n",
    "Produce your output in format below:\n",
    "\n",
    "```\n",
    "---\n",
    "<Issue title>\n",
    "\n",
    "<Brief, objective reasoning for every distinct issue you found — reference specific files, functions, or behaviors as evidence.>\n",
    "\n",
    "Rating: <TRIVIAL_CHANGES_NEEDED | COMPLEX_CHANGES_NEEDED | REDESIGN_NEEDED>\n",
    "---\n",
    "<Issue 2 title>\n",
    "\n",
    "<Brief, objective reasoning for every distinct issue you found — reference specific files, functions, or behaviors as evidence.>\n",
    "\n",
    "Rating: <TRIVIAL_CHANGES_NEEDED | COMPLEX_CHANGES_NEEDED | REDESIGN_NEEDED>\n",
    "---\n",
    "...and so on.\n",
    "```\n",
    "\n",
    "If no new issues are introduced, respond with:\n",
    "\n",
    "```\n",
    "NO_ISSUES_INTRODUCED\n",
    "```\n",
    "\n",
    "Here are your inputs:\n",
    "\n",
    "## Original migration issue\n",
    "\n",
    "{issue}\n",
    "\"\"\",\n",
    "    }\n",
    "    responses = []\n",
    "    summarize_agent = create_react_agent(\n",
    "        model=get_model(),\n",
    "        tools=[\n",
    "            inp.tools.get_architecture_tool(),\n",
    "            inp.tools.get_changed_files_tool(),\n",
    "            inp.tools.get_file_content_tool(),\n",
    "            inp.tools.get_list_files_tool(),\n",
    "            inp.tools.get_test_output_tool(),\n",
    "            inp.tools.get_compilation_issues_post_migration_tool(),\n",
    "        ],\n",
    "        prompt=RESIDUAL_EFFORT_PROMPTS[\"system\"].format(\n",
    "            source_tech=inp.source_tech,\n",
    "            target_tech=inp.target_tech,\n",
    "        ),\n",
    "    )\n",
    "    test_selectors=parse_yaml_key(inp.tc_path, \"testSelectors\")\n",
    "    response = summarize_agent.invoke(\n",
    "      {\n",
    "        \"messages\": [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": RESIDUAL_EFFORT_PROMPTS[\"user_summarize\"].format(\n",
    "                  source_tech=inp.source_tech,\n",
    "                  target_tech=inp.target_tech,\n",
    "                  issue=inp.issue,\n",
    "                  test_selectors=\"\\n- \".join(test_selectors) if test_selectors != \"__unknown__\" else \"Not available\",\n",
    "              )\n",
    "          },\n",
    "        ],\n",
    "      },\n",
    "      { \"recursion_limit\": 50 }\n",
    "    )\n",
    "    responses.append(response)\n",
    "    score = 1\n",
    "    for line in response[\"messages\"][-1].content.split(\"\\n\"):\n",
    "        if \"NO_ISSUES_INTRODUCED\" in line:\n",
    "          return 1\n",
    "        match = re.search(r\"Rating:\\s*([^\\n\\r]+)\", line)\n",
    "        if match:\n",
    "            val = float({\n",
    "              \"TRIVIAL_CHANGES_NEEDED\": 0.05,\n",
    "              \"COMPLEX_CHANGES_NEEDED\": 0.2,\n",
    "              \"REDESIGN_NEEDED\": 0.7,\n",
    "            }.get(match.group(1).strip()))\n",
    "            score -= val\n",
    "    return EvaluationResults(\n",
    "        score=round(max(score, 0), 2),\n",
    "        responses=responses,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f68b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def run_evaluation(input: EvaluationInput):\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {\n",
    "            \"completeness\": executor.submit(run_completeness_agent, input),\n",
    "            \"function_parity\": executor.submit(run_functional_correctness_agent, input),\n",
    "            \"residual_effort\": executor.submit(run_residual_effort_agent, input),\n",
    "        }\n",
    "        vals = {}\n",
    "        for k, fut in futures.items():\n",
    "            vals[k] = fut.result(timeout=180)  # raises on error/timeout\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406fa2e1",
   "metadata": {},
   "source": [
    "## Scanario 1:  Ehcache 2 to 3 upgrade\n",
    "\n",
    "| App         | Complexity |\n",
    "|-------------|------------|\n",
    "| Petclinic   |    High    |\n",
    "\n",
    "See description of the issue found [here](../apps/petclinic/test_cases/ehcache-2-to-3/tc.yaml).\n",
    "\n",
    "See notes on expected fix [here](../apps/petclinic/test_cases/ehcache-2-to-3/notes.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f4f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tools -> apply diff -> run tools\n",
    "# with agent and non-agent mode\n",
    "\n",
    "petclinic_app = TestAppCoords(\n",
    "    path=Path(\"../apps/petclinic/app.yaml\").absolute(),\n",
    ")\n",
    "\n",
    "tc_1_agent_mode: TestCaseCoords = TestCaseCoords(\n",
    "    path=Path(\"../apps/petclinic/test_cases/ehcache-2-to-3/tc.yaml\").absolute(),\n",
    "    variant=\"agent\",\n",
    "    diff_path=Path(\"test-data/diffs/ehcache-2-to-3/gpt_4o_agent.diff\").absolute(),\n",
    "    app_coords=petclinic_app,\n",
    ")\n",
    "\n",
    "tc_1_non_agent_mode: TestCaseCoords = TestCaseCoords(\n",
    "    path=Path(\"../apps/petclinic/test_cases/ehcache-2-to-3/tc.yaml\").absolute(),\n",
    "    variant=\"non-agent\",\n",
    "    diff_path=Path(\"test-data/diffs/ehcache-2-to-3/gpt_4o.diff\").absolute(),\n",
    "    app_coords=petclinic_app,\n",
    ")\n",
    "\n",
    "clone_repo(petclinic_app.url, petclinic_app.branch, petclinic_app.repo_path)\n",
    "## Agent mode\n",
    "# run tools\n",
    "run_mvn(tc=tc_1_agent_mode)\n",
    "run_mvn_test(tc=tc_1_agent_mode)\n",
    "run_kantra(tc=tc_1_agent_mode)\n",
    "# apply diff\n",
    "git_apply_diff(tc=tc_1_agent_mode)\n",
    "# run tools again\n",
    "run_mvn(tc=tc_1_agent_mode, after=True)\n",
    "run_mvn_test(tc=tc_1_agent_mode, after=True)\n",
    "run_kantra(tc=tc_1_agent_mode, after=True)\n",
    "# reset\n",
    "git_reset(tc=tc_1_agent_mode)\n",
    "## Non-agent mode\n",
    "# run tools\n",
    "run_mvn(tc=tc_1_non_agent_mode)\n",
    "run_mvn_test(tc=tc_1_non_agent_mode)\n",
    "run_kantra(tc=tc_1_non_agent_mode)\n",
    "# apply diff\n",
    "git_apply_diff(tc=tc_1_non_agent_mode)\n",
    "# run tools again\n",
    "run_mvn(tc=tc_1_non_agent_mode, after=True)\n",
    "run_mvn_test(tc=tc_1_non_agent_mode, after=True)\n",
    "run_kantra(tc=tc_1_non_agent_mode, after=True)\n",
    "# reset\n",
    "git_reset(tc=tc_1_non_agent_mode)\n",
    "# Initialize tools\n",
    "tc1_agent_tools = EvaluationTools(tc=tc_1_agent_mode)\n",
    "tc1_agent_tools.init()\n",
    "tc1_non_agent_tools = EvaluationTools(tc=tc_1_non_agent_mode)\n",
    "tc1_non_agent_tools.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0a467",
   "metadata": {},
   "source": [
    "Now we have all the data we need for pre and post fix. We will use an LLM to evaluate the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8acd8e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for agent mode ---\n",
      "Completeness score:  0.8\n",
      "Functional parity score:  1.0\n",
      "Residual effort score:  0.65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tc1_agent_results = run_evaluation(\n",
    "    EvaluationInput(\n",
    "        source_tech=\"Spring Framework 5\",\n",
    "        target_tech=\"Spring Framework 6\",\n",
    "        issue=tc_1_agent_mode.description,\n",
    "        issue_notes=(tc_1_agent_mode.path.parent / \"notes.md\").read_text(),\n",
    "        tc_path=tc_1_agent_mode.path,\n",
    "        tools=tc1_agent_tools,\n",
    "    ))\n",
    "\n",
    "print(\"--- Results for agent mode ---\")\n",
    "print(\"Completeness score: \", tc1_agent_results[\"completeness\"].score)\n",
    "print(\"Functional parity score: \", tc1_agent_results[\"function_parity\"].score)\n",
    "print(\"Residual effort score: \", tc1_agent_results[\"residual_effort\"].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in tc1_agent_results[\"residual_effort\"].responses:\n",
    "    for msg in response[\"messages\"]:\n",
    "        print(\"--------------------\")\n",
    "        print(f\"Role: {getattr(msg, 'Role', 'Unknown')}\\nContent: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b606de75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for non-agent mode ---\n",
      "Completeness score:  0.6\n",
      "Functional parity score:  0.75\n",
      "Residual effort score:  0.95\n"
     ]
    }
   ],
   "source": [
    "tc1_non_agent_results = run_evaluation(\n",
    "    EvaluationInput(\n",
    "        source_tech=\"Spring Framework 5\",\n",
    "        target_tech=\"Spring Framework 6\",\n",
    "        issue=tc_1_non_agent_mode.description,\n",
    "        issue_notes=(tc_1_non_agent_mode.path.parent / \"notes.md\").read_text(),\n",
    "        tc_path=tc_1_non_agent_mode.path,\n",
    "        tools=tc1_non_agent_tools,\n",
    "    ))\n",
    "print(\"--- Results for non-agent mode ---\")\n",
    "print(\"Completeness score: \", tc1_non_agent_results[\"completeness\"].score)\n",
    "print(\"Functional parity score: \", tc1_non_agent_results[\"function_parity\"].score)\n",
    "print(\"Residual effort score: \", tc1_non_agent_results[\"residual_effort\"].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1673b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAACMCAYAAADBR2DiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPTRJREFUeJzt3XlYVdX+P/D3PoyHGZTRQHACnGcvkrNGply11OssDpilJZmmVs5jmnPmlIma/izrZlyvXkMEL2IiypADIqKEt0AUmU2Fc9bvj2R/PZ4NomKH4P16nvM87bXX2fuzNqvjWWd99tqSEEKAiIiIiIiIagSVoQMgIiIiIiKiqsNBHhERERERUQ3CQR4REREREVENwkEeERERERFRDcJBHhERERERUQ3CQR4REREREVENwkEeERERERFRDcJBHhERERERUQ3CQR4REREREVENwkEeERFRDbJgwQJIkmToMIiIyIA4yCMiInpEaGgoJEkq93X69GlDh1gjLFu2DAcPHqx0/Vu3bmHatGnw8fGBWq2Gk5MTOnbsiFmzZqGoqOiFxkpE9FcjCSGEoYMgIiKqLkJDQzFu3DgsWrQIXl5eevtfffVV1K1b1yCxVUZpaSlKS0thbm5u6FAqZGVlhcGDByM0NPSJde/cuYM2bdqgoKAA48ePh4+PD3JycvDzzz/j0KFD+Pnnn+Hp6fmnxE1E9FdgbOgAiIiIqqO+ffuiffv2hg6j0oqLi2FpaQljY2MYG9esf9537NiBjIwMxMTEoHPnzjr7CgoKYGpq+qfFUnadiYiqM6ZrEhERPYP58+dDpVIhIiJCp3zSpEkwNTVFUlISACAqKgqSJOHrr7/Ghx9+CBcXF1haWuLvf/87bty4oXfc2NhYvPrqq7C1tYWFhQW6deuGmJgYnTpl991dunQJI0aMgL29PV5++WWdfY+SJAlTp07FgQMH0LRpU6jVavj5+eH8+fMAgK1bt6JRo0YwNzdH9+7dkZ6e/lxxXb16FUFBQbCzs4OtrS3GjRuHu3fv6sRTXFyMXbt2yWmwQUFB5V7rtLQ0GBkZ4W9/+5vePhsbG71Zy9jYWLz22muwt7eHpaUlWrZsifXr1+vUOX78OLp06QJLS0vY2dlhwIABSE5OrvR1BoCvvvoK7dq1g1qthoODA4YNG6b3N01NTcUbb7wBFxcXmJub46WXXsKwYcOQn59fbnuJiJ5Xzfqpj4iIqIrk5+fj9u3bOmWSJKFOnToAgI8//hj/+te/MGHCBJw/fx7W1tY4evQotm/fjsWLF6NVq1Y67126dCkkScKsWbOQnZ2NdevWoXfv3khMTIRarQYeDjz69u2Ldu3ayYPInTt3omfPnoiOjkbHjh11jjlkyBA0btwYy5Ytw5PuvoiOjkZYWBimTJkCAFi+fDn69++PDz74AJ9//jnefvtt5ObmYuXKlRg/fjyOHz8uv/dp4xo6dCi8vLywfPlyxMfH44svvoCTkxM++eQTAMCePXswceJEdOzYEZMmTQIANGzYsNzY69evD41Ggz179mDs2LEVtjM8PBz9+/eHq6srpk2bBhcXFyQnJ+PQoUOYNm0aAODYsWPo27cvGjRogAULFuD333/Hxo0b4e/vj/j4eL3UT6XrvHTpUsydOxdDhw7FxIkTcevWLWzcuBFdu3ZFQkIC7Ozs8ODBAwQEBOD+/ft455134OLigl9//RWHDh1CXl4ebG1tK2wLEdEzE0RERCTbuXOnAKD4MjMz06l7/vx5YWpqKiZOnChyc3NFvXr1RPv27UVJSYlcJzIyUgAQ9erVEwUFBXL5N998IwCI9evXCyGE0Gq1onHjxiIgIEBotVq53t27d4WXl5fo06ePXDZ//nwBQAwfPlwv/rJ9jyqL/fr163LZ1q1bBQDh4uKiE9ecOXMEALnus8Q1fvx4nfMPGjRI1KlTR6fM0tJSjB07tty/w6OysrKEo6OjACB8fHzE5MmTxb59+0ReXp5OvdLSUuHl5SXq168vcnNzdfY9Gnvr1q2Fk5OTyMnJkcuSkpKESqUSY8aM0WvP49c5PT1dGBkZiaVLl+qUnz9/XhgbG8vlCQkJAoA4cOBApdpJRFRVmK5JRESkYNOmTQgPD9d5HTlyRKdO8+bNsXDhQnzxxRcICAjA7du3sWvXLsV74saMGQNra2t5e/DgwXB1dcXhw4cBAImJiUhNTcWIESOQk5OD27dv4/bt2yguLkavXr3w3//+F1qtVueYkydPrnR7evXqpTND1alTJwDAG2+8oRNXWfm1a9eqLK4uXbogJycHBQUFlY73Uc7OzkhKSsLkyZORm5uLLVu2YMSIEXBycsLixYvl2bWEhARcv34dISEhsLOz0zlGWQprZmYmEhMTERQUBAcHB3l/y5Yt0adPH/nvUVF7/vnPf0Kr1WLo0KHy9bh9+zZcXFzQuHFjREZGAoA8U3f06FGddFUioheN6ZpEREQKOnbsWKmFV2bOnIn9+/fjzJkzWLZsGZo2bapYr3HjxjrbkiShUaNG8v1vqampAFBhOmJ+fj7s7e3lbaXVP8vj4eGhs102AHF3d1csz83Nfea4Hj9X2b7c3FzY2NhUOuZHubq6YvPmzfj888+RmpqKo0eP4pNPPsG8efPg6uqKiRMnIi0tDXg4+C7PL7/8AgDw9vbW2+fr64ujR4/qLa7y+HVOTU2FEELvb1rGxMREft/06dOxZs0a7N27F126dMHf//53jBo1iqmaRPRCcZBHRET0HK5duyYPhMoWMnkWZbNhq1atQuvWrRXrWFlZ6WyX3ctXGUZGRk9VXjY79ixxPemYz0OSJDRp0gRNmjRBv3790LhxY+zduxcTJ0587mOX5/HrrNVqIUkSjhw5otjWR6/H6tWrERQUhB9++AE//vgj3n33XSxfvhynT5/GSy+99MJiJqLajYM8IiKiZ6TVahEUFAQbGxuEhIRg2bJlGDx4MF5//XW9umUDwTJCCFy9ehUtW7YEHll4xMbGBr179/6TWvBkLyqux1cAfRYNGjSAvb09MjMzgUdivXDhQrmx1q9fHwCQkpKit+/y5cuoW7fuEx+R0LBhQwgh4OXlhSZNmjwxzhYtWqBFixb4+OOPcerUKfj7+2PLli1YsmRJpdpJRPS0eE8eERHRM1qzZg1OnTqFbdu2YfHixejcuTPeeustvVU5AWD37t0oLCyUt7/99ltkZmaib9++AIB27dqhYcOG+PTTT1FUVKT3/lu3br3g1ih7UXFZWloiLy+vUnVjY2NRXFysV37mzBnk5OTIqZdt27aFl5cX1q1bp3fssllEV1dXtG7dGrt27dKpc+HCBfz444947bXXnhjP66+/DiMjIyxcuFBvdlIIgZycHODhM/xKS0t19rdo0QIqlQr379+vVNuJiJ4FZ/KIiIgUHDlyBJcvX9Yr79y5Mxo0aIDk5GTMnTsXQUFBCAwMBACEhoaidevWePvtt/HNN9/ovM/BwQEvv/wyxo0bh5s3b2LdunVo1KgRgoODAQAqlQpffPEF+vbti2bNmmHcuHGoV68efv31V0RGRsLGxgb/+te//qTW/58XFVe7du1w7NgxrFmzBm5ubvDy8pIXfXncnj17sHfvXgwaNAjt2rWDqakpkpOT8eWXX8Lc3BwffvihHOvmzZsRGBiI1q1bY9y4cXB1dcXly5dx8eJFHD16FHiYetq3b1/4+flhwoQJ8iMUbG1tsWDBgifG3rBhQyxZsgRz5sxBeno6Bg4cCGtra1y/fh3ff/89Jk2ahBkzZuD48eOYOnUqhgwZgiZNmqC0tBR79uyBkZER3njjjae+ZkRElWbo5T2JiIiqk4oeoQBA7Ny5U5SWlooOHTqIl156SW8Z//Xr1wsA4uuvvxbikUco/L//9//EnDlzhJOTk1Cr1aJfv37il19+0Tt/QkKCeP3110WdOnWEmZmZqF+/vhg6dKiIiIiQ65Qt7X/r1i2995f3CIUpU6bolF2/fl0AEKtWrdIpL4v38WX/nyeusmv66CMcLl++LLp27SrUarUAUOHjFH7++Wcxc+ZM0bZtW+Hg4CCMjY2Fq6urGDJkiIiPj9erf/LkSdGnTx9hbW0tLC0tRcuWLcXGjRt16hw7dkz4+/sLtVotbGxsRGBgoLh06ZLitVS6zkII8d1334mXX35ZWFpaCktLS+Hj4yOmTJkiUlJShBBCXLt2TYwfP140bNhQmJubCwcHB9GjRw9x7NixcttKRFQVJFEVd0ETERGRoqioKPTo0QMHDhzA4MGDDR0OERHVArwnj4iIiIiIqAbhII+IiIiIiKgG4SCPiIiIiIioBuE9eURERERERDUIZ/KIiIiIiIhqEA7yiIiIiIiIahA+DJ1qJa1Wi99++w3W1taQJMnQ4RARERFRLSeEQGFhIdzc3KBSPd9cHAd5VCv99ttvcHd3N3QYREREREQ6bty4gZdeeum5jsFBHtVK1tbWAICMjAzY2toaOhyqZoQQyMvLg52dHWd6SQ/7B1WE/YMqwv5BFcnPz4eHh4f8PfV5cJBHtVLZB6uNjQ1sbGwMHQ5VM0IISJLEdF5SxP5BFWH/oIqwf1BFyh56UBV9g4M8qtXsTkqApaGjoOpHAsDB/6Mm2RwwdAhUw61JPmzoEKqMEYC7hg7iL8hy5E5Dh/DCSZLEH5epXFU58OfqmlSrSXxMJClQCQHf0hyo2D9IiQDs70sAuwcpEADyVA7sHqRICIGcnBzwMdWkpCr7BQd5VKvxI5aUCAAFkin7B5XrgYq9g8pnIh4YOgSqxkxNTQ0dAtUCTNek2o358KRASBJ+NXr+m56phpKAYhNDB0HVlQTAUhQZOgyqpsruxyNSwnRNoioiCa2hQ6BqSCW0aF56Cyr2D1IgCcDhngSJk3mkQAsJd4zqQgv+iEj6tFotbt26Ba2W/76QvqrsFxzkUbUXFRUFSZKQl5dX5ccW/EeYFAhIuC1ZsH+QIgHgnrFgOi8pkiBgrr0LiT2EFEiSBAsLC66sSYr+8jN5kiTh4MGDT/We/fv3Q5IkDBw4sMrjKRtENGvWDBqNRmefnZ0dQkNDq/yc1VV6ejokSUJiYqKhQ/lz8EOWFAhJQpaRJQT7BymRgLvGD/PyiB4jAbAQd9k9SJEkSbC0tOQgjxT95Qd5Tys9PR0zZsxAly5dXuh5rl27ht27d7/Qc1D1wnRNUqISWrQqyWa6JimSBFCX6ZpUDi0k5Bg5Ml2TFGm1WmRnZzNdkxQZLF2zsLAQI0eOhKWlJVxdXbF27Vp0794dISEhch1PT08sXrwYw4cPh6WlJerVq4dNmzbp7AeAQYMGQZIkebs8Go0GI0eOxMKFC9GgQQO9/bm5uRgzZgzs7e1hYWGBvn37IjU19WmaJXvnnXcwf/583L9/v9w6GRkZGDBgAKysrGBjY4OhQ4fi5s2b8v4FCxagdevW2LNnDzw9PWFra4thw4ahsLCwwnPv2bMH7du3h7W1NVxcXDBixAhkZ2fr1AkLC0Pjxo1hbm6OHj16YNeuXXppjCdPnkSXLl2gVqvh7u6Od999F8XFxfJ+T09PLFu2DOPHj4e1tTU8PDywbds2eb+XlxcAoE2bNpAkCd27d1eMt2z28+jRo2jTpg3UajV69uyJ7OxsHDlyBL6+vrCxscGIESNw9+7/PS3o/v37ePfdd+Hk5ARzc3O8/PLLiIuL0zn24cOH0aRJE6jVavTo0QPp6el6539SOyuL6XikREDCr0ZW7B+kSAAoYromlUOCgKW2iOmapEiSJFhZWXEmjxQZbCZv+vTpiImJQVhYGMLDwxEdHY34+Hi9eqtWrUKrVq2QkJCA2bNnY9q0aQgPDwcA+Qv9zp07kZmZqfcF/3GLFi2Ck5MTJkyYoLg/KCgIZ8+eRVhYGH766ScIIfDaa6+hpKREriNJUqVSLkNCQlBaWoqNGzcq7tdqtRgwYADu3LmDEydOIDw8HNeuXcM//vEPnXppaWk4ePAgDh06hEOHDuHEiRNYsWJFhecuKSnB4sWLkZSUhIMHDyI9PR1BQUHy/uvXr2Pw4MEYOHAgkpKS8Oabb+Kjjz7SO++rr76KN954Az///DO+/vprnDx5ElOnTtWpt3r1arRv3x4JCQl4++238dZbbyElJQUAcObMGQDAsWPHkJmZiX/+858Vxr1gwQJ89tlnOHXqFG7cuIGhQ4di3bp12LdvH/7973/jxx9/1LmeH3zwAb777jvs2rUL8fHxaNSoEQICAnDnzh0AwI0bN/D6668jMDAQiYmJmDhxImbPnv1M7awUfsiSAiFJuK2yYLomKZOAe0zXpHJIAMzF7+wepIj35FFFqrJfVPoRCoWFhdi1axf27duHXr16AQ8Ham5ubnp1/f395S/mTZo0QUxMDNauXYs+ffrA0dEReHivm4uLS4XnPHnyJHbs2FHu/WGpqakICwtDTEwMOnfuDADYu3cv3N3dcfDgQQwZMgQA4O3tDVtb2ye20cLCAvPnz8eHH36I4OBgvfdERETg/PnzuH79Otzd3QEAu3fvRrNmzRAXF4cOHToADweDoaGh8hK5o0ePRkREBJYuXVruucePHy//d4MGDbBhwwZ06NABRUVFsLKywtatW+Ht7Y1Vq1bJbbpw4YLOMZcvX46RI0fKM6uNGzfGhg0b0K1bN2zevBnm5uYAgNdeew1vv/02AGDWrFlYu3YtIiMj4e3tLf996tSp88S/DwAsWbIE/v7+AIAJEyZgzpw5SEtLk2ddBw8ejMjISMyaNQvFxcXYvHkzQkND0bdvXwDA9u3bER4ejh07dmDmzJnYvHkzGjZsiNWrV8vtPH/+PD755JOnbuej7t+/rzNDW1BQADxM1+RvrfQ4ldCiTektJBg7Qiv9JbLa6U9Ulq5521xA8HsaPeaP1TWd4KDJhor/wtBjylbXdHR0hErFf19Il0HSNa9du4aSkhJ07NhRLrO1tYW3t7deXT8/P73t5OTkco+dkZEBKysr+bVs2TIUFhZi9OjR2L59O+rWrav4vuTkZBgbG6NTp05yWZ06deDt7a1zvsuXL2PQoEGVaueECRNQp04dnUHFo+dzd3eXB3gA0LRpU9jZ2emcz9PTU+cZKK6urnLq5d69e3XaGh0dDQA4d+4cAgMD4eHhAWtra3Tr1k2+NgCQkpIiDyLLPPq3AICkpCSEhobqHD8gIABarRbXr1+X67Vs2VL+b0mS4OLiopcaWlmPHsvZ2RkWFhY6abXOzs7ysdPS0lBSUiIPCgHAxMQEHTt2lK9fcnKyzt8TCv2psu181PLly2Frayu/yv6GTMcjJVpIuGZky3tqSJEAUGDKdE1SJkHAWpvHdE1SJEkSbG1tOZNHigwyk/ciubm56czWOTg4IC0tDenp6QgMDJTLy0a3xsbGcnphVTM2NsbSpUsRFBT0bOl/Dwcuj5IkSY7973//u84gpl69eiguLkZAQAACAgKwd+9eODo6IiMjAwEBAXjw4EGlz1tUVIQ333wT7777rt4+Dw+PSsX3tB49liRJVXrs8lS2nY+aM2cOpk+fLm8XFBT8MdDjhywpkSTkSvozwkTAH/l4940MHQRVVxIAM1H+vf1Uu0mSpJhxRARDDfIaNGgAExMTxMXFyV+k8/PzceXKFXTt2lWn7unTp/W2fX195W0TExOdRxUYGxujUaNGOu+xsLDA+fPndco+/vhjFBYWYv369XB3d4dWq0VpaSliY2PldM2cnBykpKSgadOmlW2aniFDhmDVqlVYuHChTrmvry9u3LiBGzduyDNBly5dQl5eXqXPZ21trTPLh4ezeDk5OVixYoV83LNnz+rU8fb2xuHDh3XKHr+fsW3btrh06ZLetXwapqamwMMFb6paw4YNYWpqipiYGNSvXx94eC9iXFycnHrp6+uLsLAwnfc93p+epZ1mZmYwMzPTK1cJLbi+FT3OSGjRvvQmzho7Q8N0TXqMJACn3yVkq5muSfq0kHDbyAV1NVlM1yQ9Wq0WN2/ehLOzM9M1SY9B0jWtra0xduxYzJw5E5GRkbh48SImTJgAlUqlN+qMiYnBypUrceXKFWzatAkHDhzAtGnT5P2enp6IiIhAVlYWcnNzFc9nbm6O5s2b67zs7OxgbW2N5s2bw9TUFI0bN8aAAQMQHByMkydPIikpCaNGjUK9evUwYMAA+Vg+Pj74/vvvn+rCrFixAl9++aXOio29e/dGixYtMHLkSMTHx+PMmTMYM2YMunXrhvbt2z/V8R/l4eEBU1NTbNy4EdeuXUNYWBgWL16sU+fNN9/E5cuXMWvWLFy5cgXffPONvJhM2fWfNWsWTp06halTpyIxMRGpqan44YcfnmpG0snJCWq1Gv/5z39w8+ZN5OfnP3O7HmdpaYm33noLM2fOxH/+8x9cunQJwcHBuHv3rrywzuTJk5GamoqZM2ciJSUF+/bt01s0pyraWYbpeKREAwmXjBygYf8gBQLAHTOma5IyCQJ2mhyma5IiSZLg4ODAdE1SZLDVNdesWQM/Pz/0798fvXv3hr+/P3x9ffWmnd9//32cPXsWbdq0wZIlS7BmzRoEBATI+1evXo3w8HC4u7ujTZs2z9WAnTt3ol27dujfvz/8/PwghMDhw4d10gZTUlKeerDSs2dP9OzZE6WlpXKZJEn44YcfYG9vj65du6J3795o0KABvv766+dqg6OjI0JDQ3HgwAE0bdoUK1aswKeffqpTx8vLC99++y3++c9/omXLlti8ebO8umbZDFXLli1x4sQJXLlyBV26dEGbNm0wb948xcVxymNsbIwNGzZg69atcHNz0xksV4UVK1bgjTfewOjRo9G2bVtcvXoVR48ehb29PfBwwPvdd9/h4MGDaNWqFbZs2YJly5bpHKMq2injhywpkSQUqszYP0iZBJQYcXVNUiYBMMUDdg9SJEkSzMzMOMgjRVXZLyQhxDP/1FRcXIx69eph9erV8kyMp6cnQkJCdJ6dRy/G0qVLsWXLFty4ccPQofzlFBQUwNbWFqp/5UJrZWfocKiaMRJadCzNwhljF6ZrPjTJ5oChQ6g2JAE4/y7hJtM1q9Sa5MOVqFX9aSHhlpErHDWZTNd8SpYjdxo6hBdOq9UiKysLLi4uTNckPXl5ebC3t0d+fj5sbGye61hPtfBKQkICLl++jI4dOyI/Px+LFi0CgCqf7SFln3/+OTp06IA6deogJiYGq1ateubFYegPTNckJRpISDJ2ZLomKRLAH49PMHQgVC1JEKijyWa6JimSJAmOjo6cySNFBl1d89NPP0VKSgpMTU3Rrl07REdHl/uIA6paqampWLJkCe7cuQMPDw+8//77mDNnjqHD+mvjhywpkSTchUklKlKtJAGl/OigckgAjFFaiZpUGymtRE5UptqkaxL9VTFdkypiJLToXPIbTpm4MV3zIaZr/h9JAC53Vciy0DJdswrVpHTNbGM3OJX+xnTNp1Rb0jV/++03uLm5MV2T9FRluiZ7F9VqTNckJRpIiDVxYbomKRIAbqq1/PpOiiQIOJZmMV2TFEmSBBcXF6ZrkiKDra5JVOPwQ5aUSBI0ULF/kDIJf8zgsXuQgj+6Bn9CJGWSJCk+fowIhr4nj6gmyfXXwo7ZmvQYptMoGWLoAKoN9o8XpG3N6GPsH1QR9g+qiEEehk5UE/EDlpSoVCr+A0zlYv+girB/UEXYP6giVdkv2MOoVuO6Q6RECAGtVsv+QYrYP6gi7B9UEfYPqkhV9gsO8qhW44csKRFCICsri/2DFLF/UEXYP6gi7B9UkarsF3yEAtVKZY9QqIolaomIiIiInldVfj/lwitUq9n+VwBWho6Cqh0hYIFS3IUxV9gkfULgbetv/3ggOrsHPU4AxgLsH4+oKc9ArAoCgAbGMEJplXWP2vB8wdqC6ZpEVYQPqiUlRhBoVXoLRuwfpMAIAnXvSfz+TookgP2DyiUgIcfICYI9hBRU5SCPM3lUq2kl/s5B+jSSCj+ZuBk6DKqmNJIKWRb8AYCUCQnsH1QuFQScNb8ZOgyqpri6JlFV4S2ppEQIWGvvs3+QMiFgonmYd0X0OAH2DyqXAPAApuwepIjpmkRVhOmapMQIAk01d5iuSYqMIOBwn+l4pEwC2D+oXAIS8ozqMF2TFDFdk6iKMF2TlGgkFWJNXA0dBlVTGkmFm0zHo3IICewfVC4VBJw0mYYOg6oppmtSrePp6Yl169ZV/YGZjkdKhIC99h77BykTAmZMx6PyCLB/ULkEgPuSGbsHKWK65nOSJAkHDx58qvfs378fkiRh4MCBLywuAPDx8YGZmRmysrJe6Hkq0r17d4SEhBjs/H8miR+zpEAFgQaafKbzkiIVBGweMB2PlEkA+weVS0BCocqO6ZqkiIO8P1l6ejpmzJiBLl26vNDznDx5Er///jsGDx6MXbt2vdBz0R8E0zVJgVZS4ZyJM9N5SZFWUuGWWkDwOxopEBLYP6hcKgjU1dzkj4ikqNamaxYWFmLkyJGwtLSEq6sr1q5dqzfr5OnpicWLF2P48OGwtLREvXr1sGnTJp39ADBo0CBIkiRvl0ej0WDkyJFYuHAhGjRooLc/NzcXY8aMgb29PSwsLNC3b1+kpqY+U/t27NiBESNGYPTo0fjyyy/19mdmZqJfv35Qq9Xw8vLCvn379NIY8/LyMHHiRDg6OsLGxgY9e/ZEUlKSvH/BggVo3bo19uzZA09PT9ja2mLYsGEoLCwEAAQFBeHEiRNYv349JEmCJElIT09XjNfT0xNLlizBmDFjYGVlhfr16yMsLAy3bt3CgAEDYGVlhZYtW+Ls2bM67/vuu+/QrFkzmJmZwdPTE6tXr9bZn52djcDAQLmde/fu1Tv3k9pZaUzHIwWSEKirvQuJ/YMUSELAvJTpeFQOAfYPKpcAcE9Ss3uQolo7kzd9+nTExMQgLCwM4eHhiI6ORnx8vF69VatWoVWrVkhISMDs2bMxbdo0hIeHAwDi4uIAADt37kRmZqa8XZ5FixbByckJEyZMUNwfFBSEs2fPIiwsDD/99BOEEHjttddQUlIi15EkCaGhoRWep7CwEAcOHMCoUaPQp08f5OfnIzo6WqfOmDFj8NtvvyEqKgrfffcdtm3bhuzsbJ06Q4YMQXZ2No4cOYJz586hbdu26NWrF+7cuSPXSUtLw8GDB3Ho0CEcOnQIJ06cwIoVKwAA69evh5+fH4KDg5GZmYnMzEy4u7uXG/fatWvh7++PhIQE9OvXD6NHj8aYMWMwatQoxMfHo2HDhhgzZozcac+dO4ehQ4di2LBhOH/+PBYsWIC5c+fqXJ+goCDcuHEDkZGR+Pbbb/H5558/Uzsfdf/+fRQUFOi8wHRNKocEgXqaIvYPUiRBwKqU6XikTALYP6hcAhKKVVZM1yRFtXJ1zcLCQuzatQv79u1Dr169gIcDNTc3/QcW+/v7Y/bs2QCAJk2aICYmBmvXrkWfPn3g6OgIALCzs4OLi0uF5zx58iR27NiBxMRExf2pqakICwtDTEwMOnfuDADYu3cv3N3dcfDgQQwZMgQA4O3tDVtb2wrPtX//fjRu3BjNmjUDAAwbNgw7duyQU0QvX76MY8eOIS4uDu3btwcAfPHFF2jcuLFOvGfOnEF2djbMzMwAAJ9++ikOHjyIb7/9FpMmTQIAaLVahIaGwtraGgAwevRoREREYOnSpbC1tYWpqSksLCyeeH0A4LXXXsObb74JAJg3bx42b96MDh06yG2fNWsW/Pz8cPPmTbi4uGDNmjXo1asX5s6dCzz8+1y6dAmrVq1CUFAQrly5giNHjuDMmTPo0KED8HCG09fX96nb+ajly5dj4cKFeuVM1yQlWkmFJBMnQ4dB1ZRWUuG2OX8AIGVCAvsHlUsFgTqaW4YOg6qpWpmuee3aNZSUlKBjx45yma2tLby9vfXq+vn56W0nJyeXe+yMjAxYWVnJr2XLlqGwsBCjR4/G9u3bUbduXcX3JScnw9jYGJ06dZLL6tSpA29vb53zXb58GYMGDaqwfV9++SVGjRolb48aNQoHDhyQ0yhTUlJgbGyMtm3bynUaNWoEe3t7eTspKQlFRUWoU6eOTnuuX7+OtLQ0uZ6np6c8wAMAV1dXvZmyymrZsqX8387OzgCAFi1a6JWVHT85ORn+/v46x/D390dqaio0Go18Tdu1ayfv9/HxgZ2d3VO381Fz5sxBfn6+/Lpx48YfO5iORwokIeCiKWa6JimShIAF0/GoPALsH1QuAeCuZMHuQYpq5Uzei+Tm5qYzW+fg4IC0tDSkp6cjMDBQLtdqtQAAY2NjpKSkVNn5L126hNOnT+PMmTOYNWuWXK7RaLB//34EBwdX6jhFRUVwdXVFVFSU3r5HB0kmJiY6+yRJktv2tB49liRJ5ZY96/GVVLadjzIzM5Nn/R4lQfCDlvRIEKgr7iIbaqbUkB4JAualEn434ucH6ZMA9g8ql4CEeyoLmGt+5y0BpKdWDvIaNGgAExMTxMXFwcPDAwCQn5+PK1euoGvXrjp1T58+rbf9aLqfiYkJNBqNvG1sbIxGjRrpvMfCwgLnz5/XKfv4449RWFiI9evXw93dHVqtFqWlpYiNjZXTNXNycpCSkoKmTZtWum07duxA165ddRaIwcN01B07diA4OBje3t4oLS1FQkKCPMt19epV5ObmyvXbtm2LrKwsGBsbP3FBmYqYmprqXJ+q5Ovri5iYGJ2ymJgYNGnSBEZGRvDx8UFpaSnOnTsnp2umpKQgLy9Prl9V7QTTNakcWkmFC8aOhg6DqimtpMIdpuNROYQE9g8qlwoCDprbhg6Dqqlama5pbW2NsWPHYubMmYiMjMTFixcxYcIEqFQqebaoTExMDFauXIkrV65g06ZNOHDgAKZNmybv9/T0REREBLKysnQGSY8yNzdH8+bNdV52dnawtrZG8+bNYWpqisaNG2PAgAEIDg7GyZMnkZSUhFGjRqFevXoYMGCAfCwfHx98//33iucpKSnBnj17MHz4cL3zTZw4EbGxsbh48SJ8fHzQu3dvTJo0CWfOnEFCQgImTZoEtVott793797w8/PDwIED8eOPPyI9PR2nTp3CRx99pLfCZUU8PT0RGxuL9PR03L59u0pn4d5//31ERERg8eLFuHLlCnbt2oXPPvsMM2bMAB7ev/jqq6/izTffRGxsLM6dO4eJEydCrVbLx6iqdgJM1yRlkhCopylkuiYpkoSAZQnT8agcAuwfVC4BoFiyYvcgRbV2dc01a9bAz88P/fv3R+/eveHv7w9fX1+Ym5vr1Hv//fdx9uxZtGnTBkuWLMGaNWsQEBAg71+9ejXCw8Ph7u6ONm3aPFdMO3fuRLt27dC/f3/4+flBCIHDhw/rpCympKQgPz9f8f1hYWHIyclRvGfP19cXvr6+2LFjBwBg9+7dcHZ2RteuXTFo0CAEBwfD2tpabr8kSTh8+DC6du2KcePGoUmTJhg2bBh++eUX+d64ypgxYwaMjIzQtGlTODo6IiMj4xmujLK2bdvim2++wf79+9G8eXPMmzcPixYtQlBQkFynbEGdbt264fXXX8ekSZPg5PR/i2BUVTvxMK2G6HESABvxgP2DFEkATLXsHVQ+9g+qSIlkaugQqBaQRFUOGf9kxcXFqFevHlavXi0/4sDT0xMhISE6z86rqf73v//B3d0dx44dk1ccpcopKCj4Y8XTQ/mApY2hwyGiv5hJNgcMHQLRX8aa5MOGDqFGsxy509AhUBUp+36an58PG5vn+376l7knDwASEhJw+fJldOzYEfn5+Vi0aBEA6KRG1mTHjx9HUVERWrRogczMTHzwwQfw9PTUuyeRnsJf9zcOeoEkIeChLUSGyhpC4i/ypEsSAtYPJBSaCKYDkD4BWJewf5AyAaBYZQNLbQG7B+mplQuvlPn000+RkpICU1NTtGvXDtHR0eU+4qCmKSkpwYcffohr167B2toanTt3xt69e/VWy6TKk3jbBCmQAJgKDfsHKZIAqNgxqALsH1QRzV/rbin6i/pLDfLatGmDc+fOVVgnPT39T4vnzxYQEKBzbyE9P87SkBKtJCHV2L4SNak20koS8s34LZ7KIYH9g8olAbDV5lWiJtVGjy8m+Tz4UwLValw9kZSohEADTR5U7B+kQCUEbB5InOYlZQLsH1QuAaBAZcvuQYpqdbomUVXK7QLY2ho6CqpuhADy8//oG5zspcf90T96w9bWtkp/daWaQQiB/Px89o9HtR1i6AiqDSEESvPzYcn+QS8YB3lUq/EDlpRIkgQ7OztDh0HVFPsHVYT9gyrC/kEVqcrvpRzkUa1UNh1e3vMLqXYTQiAvLw92dnb8IYD0sH9QRdg/qCLsH1SRsu+lVZG2yUEe1Uo5OTkAAA8PD0OHQkREREQky8nJ+eN5zs+BgzyqlRwcHAAAGRkZz/0/EdU8BQUFcHd3x40bN577YaRU87B/UEXYP6gi7B9Ukfz8fHh4eMjfU58HB3lUK6lUfywsa2tryw9ZKpeNjQ37B5WL/YMqwv5BFWH/oIqUfU99rmNUSSRERERERERULXCQR0REREREVINwkEe1kpmZGebPnw8zMzNDh0LVEPsHVYT9gyrC/kEVYf+gilRl/5BEVT5anYiIiIiIiAyKM3lEREREREQ1CAd5RERERERENQgHeURERERERDUIB3lU62zatAmenp4wNzdHp06dcObMGUOHRNXA8uXL0aFDB1hbW8PJyQkDBw5ESkqKocOiamrFihWQJAkhISGGDoWqkV9//RWjRo1CnTp1oFar0aJFC5w9e9bQYVE1oNFoMHfuXHh5eUGtVqNhw4ZYvHgxuDRG7fTf//4XgYGBcHNzgyRJOHjwoM5+IQTmzZsHV1dXqNVq9O7dG6mpqU91Dg7yqFb5+uuvMX36dMyfPx/x8fFo1aoVAgICkJ2dbejQyMBOnDiBKVOm4PTp0wgPD0dJSQleeeUVFBcXGzo0qmbi4uKwdetWtGzZ0tChUDWSm5sLf39/mJiY4MiRI7h06RJWr14Ne3t7Q4dG1cAnn3yCzZs347PPPkNycjI++eQTrFy5Ehs3bjR0aGQAxcXFaNWqFTZt2qS4f+XKldiwYQO2bNmC2NhYWFpaIiAgAPfu3av0Obi6JtUqnTp1QocOHfDZZ58BALRaLdzd3fHOO+9g9uzZhg6PqpFbt27ByckJJ06cQNeuXQ0dDlUTRUVFaNu2LT7//HMsWbIErVu3xrp16wwdFlUDs2fPRkxMDKKjow0dClVD/fv3h7OzM3bs2CGXvfHGG1Cr1fjqq68MGhsZliRJ+P777zFw4EDg4Syem5sb3n//fcyYMQMAkJ+fD2dnZ4SGhmLYsGGVOi5n8qjWePDgAc6dO4fevXvLZSqVCr1798ZPP/1k0Nio+snPzwcAODg4GDoUqkamTJmCfv366XyOEAFAWFgY2rdvjyFDhsDJyQlt2rTB9u3bDR0WVROdO3dGREQErly5AgBISkrCyZMn0bdvX0OHRtXM9evXkZWVpfPvjK2tLTp16vRU31eNX1B8RNXO7du3odFo4OzsrFPu7OyMy5cvGywuqn60Wi1CQkLg7++P5s2bGzocqib279+P+Ph4xMXFGToUqoauXbuGzZs3Y/r06fjwww8RFxeHd999F6amphg7dqyhwyMDmz17NgoKCuDj4wMjIyNoNBosXboUI0eONHRoVM1kZWUBD7+fPsrZ2VneVxkc5BERPWbKlCm4cOECTp48aehQqJq4ceMGpk2bhvDwcJibmxs6HKqGtFot2rdvj2XLlgEA2rRpgwsXLmDLli0c5BG++eYb7N27F/v27UOzZs2QmJiIkJAQuLm5sX/QC8F0Tao16tatCyMjI9y8eVOn/ObNm3BxcTFYXFS9TJ06FYcOHUJkZCReeuklQ4dD1cS5c+eQnZ2Ntm3bwtjYGMbGxjhx4gQ2bNgAY2NjaDQaQ4dIBubq6oqmTZvqlPn6+iIjI8NgMVH1MXPmTMyePRvDhg1DixYtMHr0aLz33ntYvny5oUOjaqbsO+nzfl/lII9qDVNTU7Rr1w4RERFymVarRUREBPz8/AwaGxmeEAJTp07F999/j+PHj8PLy8vQIVE10qtXL5w/fx6JiYnyq3379hg5ciQSExNhZGRk6BDJwPz9/fUeu3LlyhXUr1/fYDFR9XH37l2oVLpfu42MjKDVag0WE1VPXl5ecHFx0fm+WlBQgNjY2Kf6vsp0TapVpk+fjrFjx6J9+/bo2LEj1q1bh+LiYowbN87QoZGBTZkyBfv27cMPP/wAa2trOe/d1tYWarXa0OGRgVlbW+vdn2lpaYk6derwvk0CALz33nvo3Lkzli1bhqFDh+LMmTPYtm0btm3bZujQqBoIDAzE0qVL4eHhgWbNmiEhIQFr1qzB+PHjDR0aGUBRURGuXr0qb1+/fh2JiYlwcHCAh4cHQkJCsGTJEjRu3BheXl6YO3cu3Nzc5BU4K4OPUKBa57PPPsOqVauQlZWF1q1bY8OGDejUqZOhwyIDkyRJsXznzp0ICgr60+Oh6q979+58hALpOHToEObMmYPU1FR4eXlh+vTpCA4ONnRYVA0UFhZi7ty5+P7775GdnQ03NzcMHz4c8+bNg6mpqaHDoz9ZVFQUevTooVc+duxYhIaGQgiB+fPnY9u2bcjLy8PLL7+Mzz//HE2aNKn0OTjIIyIiIiIiqkF4Tx4REREREVENwkEeERERERFRDcJBHhERERERUQ3CQR4REREREVENwkEeERERERFRDcJBHhERERERUQ3CQR4REREREVENwkEeERERERFRDcJBHhER0QsUFRUFSZKQl5dX6fcsWLAArVu3fqFxPap79+4ICQn50873Z5g7dy4mTZpk6DB0bNmyBYGBgYYOg4hqAQ7yiIiIHn4Bt7a2RmlpqVxWVFQEExMTdO/eXadu2cAtLS3ticft3LkzMjMzYWtrW6Xx/pkDM41GgxUrVsDHxwdqtRoODg7o1KkTvvjiiz/l/E8rKysL69evx0cffaRTvmnTJnh6esLc3BydOnXCmTNnKn3MpUuXonPnzrCwsICdnZ1inYyMDPTr1w8WFhZwcnLCzJkzdfrT+PHjER8fj+jo6OdoHRHRk3GQR0REBKBHjx4oKirC2bNn5bLo6Gi4uLggNjYW9+7dk8sjIyPh4eGBhg0bPvG4pqamcHFxgSRJLyz2F23hwoVYu3YtFi9ejEuXLiEyMhKTJk16qtnJp/XgwYNnfu8XX3yBzp07o379+nLZ119/jenTp2P+/PmIj49Hq1atEBAQgOzs7ErHM2TIELz11luK+zUaDfr164cHDx7g1KlT2LVrF0JDQzFv3jy5jqmpKUaMGIENGzY8c9uIiCqDgzwiIiIA3t7ecHV1RVRUlFwWFRWFAQMGwMvLC6dPn9Yp79GjBwBAq9Vi+fLl8PLyglqtRqtWrfDtt9/q1H08XXP79u1wd3eHhYUFBg0ahDVr1ijODu3Zsweenp6wtbXFsGHDUFhYCAAICgrCiRMnsH79ekiSBEmSkJ6eDgC4cOEC+vbtCysrKzg7O2P06NG4ffu2fMzi4mKMGTMGVlZWcHV1xerVq594bcLCwvD2229jyJAh8PLyQqtWrTBhwgTMmDFDrqPVarFy5Uo0atQIZmZm8PDwwNKlS+X958+fR8+ePaFWq1GnTh1MmjQJRUVF8v6goCAMHDgQS5cuhZubG7y9vQEAN27cwNChQ2FnZwcHBwcMGDBAbmt59u/fr5cWuWbNGgQHB2PcuHFo2rQptmzZAgsLC3z55ZdPbD8eDnTfe+89tGjRQnH/jz/+iEuXLuGrr75C69at0bdvXyxevBibNm3SGbAGBgYiLCwMv//+e6XOS0T0LDjIIyIieqhHjx6IjIyUtyMjI9G9e3d069ZNLv/9998RGxsrD/KWL1+O3bt3Y8uWLbh48SLee+89jBo1CidOnFA8R0xMDCZPnoxp06YhMTERffr00RkMlUlLS8PBgwdx6NAhHDp0CCdOnMCKFSsAAOvXr4efnx+Cg4ORmZmJzMxMuLu7Iy8vDz179kSbNm1w9uxZ/Oc//8HNmzcxdOhQ+bgzZ87EiRMn8MMPP+DHH39EVFQU4uPjK7wuLi4uOH78OG7dulVunTlz5mDFihWYO3cuLl26hH379sHZ2Rl4OLAMCAiAvb094uLicODAARw7dgxTp07VOUZERARSUlIQHh6OQ4cOoaSkBAEBAbC2tkZ0dDRiYmJgZWWFV199tdyZvjt37uDSpUto3769XPbgwQOcO3cOvXv3lstUKhV69+6Nn376qcK2V9ZPP/2EFi1ayG0GgICAABQUFODixYtyWfv27VFaWorY2NgqOS8RkSJBREREQgghtm/fLiwtLUVJSYkoKCgQxsbGIjs7W+zbt0907dpVCCFERESEACB++eUXce/ePWFhYSFOnTqlc5wJEyaI4cOHCyGEiIyMFABEbm6uEEKIf/zjH6Jfv3469UeOHClsbW3l7fnz5wsLCwtRUFAgl82cOVN06tRJ3u7WrZuYNm2aznEWL14sXnnlFZ2yGzduCAAiJSVFFBYWClNTU/HNN9/I+3NycoRardY71qMuXrwofH19hUqlEi1atBBvvvmmOHz4sLy/oKBAmJmZie3btyu+f9u2bcLe3l4UFRXJZf/+97+FSqUSWVlZQgghxo4dK5ydncX9+/flOnv27BHe3t5Cq9XKZffv3xdqtVocPXpU8VwJCQkCgMjIyJDLfv31VwFA7+80c+ZM0bFjx3LbrWTnzp06f6sywcHBete+uLhYANC5VkIIYW9vL0JDQ5/qvERET4MzeURERA91794dxcXFiIuLQ3R0NJo0aQJHR0d069ZNvi8vKioKDRo0gIeHB65evYq7d++iT58+sLKykl+7d+8ud1GWlJQUdOzYUafs8W0A8PT0hLW1tbzt6ur6xPvHkpKSEBkZqROLj48P8HBmMC0tDQ8ePECnTp3k9zg4OMipkeVp2rQpLly4gNOnT2P8+PHIzs5GYGAgJk6cCABITk7G/fv30atXL8X3Jycno1WrVrC0tJTL/P39odVqkZKSIpe1aNECpqamOu25evUqrK2t5fY4ODjg3r175V7fsjRIc3PzCtv0uMmTJ+tct7LXi6BWq3H37t0XcmwiIgAwNnQARERE1UWjRo3w0ksvITIyErm5uejWrRsAwM3NDe7u7jh16hQiIyPRs2dP4OHqmwDw73//G/Xq1dM5lpmZ2XPFYmJiorMtSRK0Wm2F7ykqKkJgYCA++eQTvX2urq64evXqM8ejUqnQoUMHdOjQASEhIfjqq68wevRofPTRR1Cr1c983Ec9OgjEw/a0a9cOe/fu1avr6OioeIy6desCAHJzc+U6devWhZGREW7evKlT9+bNm3BxcQEALFq0SOcew6fl4uKit1pn2fnKzlHmzp075cZPRFQVOJNHRET0iB49eiAqKgpRUVE6j07o2rUrjhw5gjNnzsj34zVt2hRmZmbIyMhAo0aNdF7u7u6Kx/f29kZcXJxO2ePblWFqagqNRqNT1rZtW1y8eBGenp568VhaWqJhw4YwMTHRuR8sNzcXV65ceerzN23aFHh4v13jxo2hVqsRERGhWNfX1xdJSUkoLi6Wy2JiYqBSqSqcRWzbti1SU1Ph5OSk157yHknRsGFD2NjY4NKlS3KZqakp2rVrpxOfVqtFREQE/Pz8AEDxHI0aNar09fDz88P58+d1ZlvDw8NhY2MjXys8nFG9d+8e2rRpU+ljExE9LQ7yiIiIHtGjRw+cPHkSiYmJ8kweAHTr1g1bt27FgwcP5EGetbU1ZsyYgffeew+7du1CWloa4uPjsXHjRuzatUvx+O+88w4OHz6MNWvWIDU1FVu3bsWRI0ee+hELnp6eiI2NRXp6Om7fvg2tVospU6bgzp07GD58OOLi4pCWloajR49i3Lhx0Gg0sLKywoQJEzBz5kwcP34cFy5cQFBQEFSqir8ODB48GGvXrkVsbCx++eUXREVFYcqUKWjSpAl8fHxgbm6OWbNm4YMPPpBTVU+fPo0dO3YAAEaOHAlzc3OMHTsWFy5cQGRkJN555x2MHj1aZ6GSx40cORJ169bFgAEDEB0djevXryMqKgrvvvsu/ve//ym+p2xBlZMnT+qUT58+Hdu3b8euXbuQnJyMt956C8XFxRg3blylrndGRgYSExORkZEBjUaDxMREJCYmyrO5r7zyCpo2bYrRo0cjKSkJR48exccff4wpU6bozOpGR0ejQYMGlXr8BhHRMzP0TYFERETVyfXr1wUA4ePjo1Oenp4uAAhvb2+dcq1WK9atWye8vb2FiYmJcHR0FAEBAeLEiRNCKCy8Ih4uRFKvXj2hVqvFwIEDxZIlS4SLi4u8f/78+aJVq1Y651m7dq2oX7++vJ2SkiL+9re/CbVaLQCI69evCyGEuHLlihg0aJCws7MTarVa+Pj4iJCQEHnxksLCQjFq1ChhYWEhnJ2dxcqVKxUXcXnUtm3bRI8ePYSjo6MwNTUVHh4eIigoSKSnp8t1NBqNWLJkiahfv74wMTERHh4eYtmyZfL+n3/+WfTo0UOYm5sLBwcHERwcLAoLC+X9Y8eOFQMGDNA7d2ZmphgzZoyoW7euMDMzEw0aNBDBwcEiPz+/3HgPHz4s6tWrJzQajU75xo0bhYeHhzA1NRUdO3YUp0+fLvcYjxs7dqwAoPeKjIyU66Snp4u+ffsKtVot6tatK95//31RUlKic5xXXnlFLF++vNLnJSJ6FpIQQhh6oElERFSbBQcH4/Lly4iOjjZ0KDWCEAKdOnXCe++9h+HDhxs6HNnFixfRs2dPXLlypdx0UyKiqsB0TSIioj/Zp59+Kq8cWZbaOXbsWEOHVWNIkoRt27ahtLTU0KHoyMzMxO7duznAI6IXjjN5REREf7KhQ4ciKioKhYWFaNCgAd555x1MnjzZ0GEREVENwUEeERERERFRDcJ0TSIiIiIiohqEgzwiIiIiIqIahIM8IiIiIiKiGoSDPCIiIiIiohqEgzwiIiIiIqIahIM8IiIiIiKiGoSDPCIiIiIiohqEgzwiIiIiIqIahIM8IiIiIiKiGuT/A2OGWIAbjtnPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [\n",
    "    [\n",
    "    ExperimentResults(\n",
    "        title=\"Agent mode\",\n",
    "        completeness=tc1_agent_results[\"completeness\"].score,\n",
    "        functional_parity=tc1_agent_results[\"function_parity\"].score,\n",
    "        residual_effort=tc1_agent_results[\"residual_effort\"].score,\n",
    "    ),\n",
    "    ExperimentResults(\n",
    "        title=\"Non-agent mode\",\n",
    "        completeness=tc1_non_agent_results[\"completeness\"].score,\n",
    "        functional_parity=tc1_non_agent_results[\"function_parity\"].score,\n",
    "        residual_effort=tc1_non_agent_results[\"residual_effort\"].score,\n",
    "    )\n",
    "    ], \n",
    "]\n",
    "plot_scores_grouped(\n",
    "    results,\n",
    "    [\"gpt-4o\"],\n",
    "    weights=(0.5, 0.3, 0.2),\n",
    "    scale=10.0,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
